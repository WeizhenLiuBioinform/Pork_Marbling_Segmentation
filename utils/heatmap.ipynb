{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# from models.vgg_unet3 import VGGUNET2\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvgg_unet3\u001b[39;00m \u001b[39mimport\u001b[39;00m VGGUNET2\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmyimshows\u001b[39m(imgs, titles\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, fname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest.jpg\u001b[39m\u001b[39m\"\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m):\n\u001b[1;32m     11\u001b[0m     lens \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(imgs)\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import torchvision\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from models.vgg_unet3 import VGGUNET2\n",
    "\n",
    "def myimshows(imgs, titles=False, fname=\"test.jpg\", size=6):\n",
    "    lens = len(imgs)\n",
    "    fig = plt.figure(figsize=(size * lens,size))\n",
    "    if titles == False:\n",
    "        titles=\"0123456789\"\n",
    "    for i in range(1, lens + 1):\n",
    "        cols = 100 + lens * 10 + i\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.subplot(cols)\n",
    "        if len(imgs[i - 1].shape) == 2:\n",
    "            plt.imshow(imgs[i - 1], cmap='Reds')\n",
    "        else:\n",
    "            plt.imshow(imgs[i - 1])\n",
    "        plt.title(titles[i - 1])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.savefig(fname, bbox_inches='tight')\n",
    "    plt.show()\n",
    "def tensor2img(tensor,heatmap=False,shape=(400,800)):\n",
    "    np_arr=tensor.detach().numpy()#[0]\n",
    "    #对数据进行归一化\n",
    "    if np_arr.max()>1 or np_arr.min()<0:\n",
    "        np_arr=np_arr-np_arr.min()\n",
    "        np_arr=np_arr/np_arr.max()\n",
    "    #np_arr=(np_arr*255).astype(np.uint8)\n",
    "    if np_arr.shape[0]==1:\n",
    "        np_arr=np.concatenate([np_arr,np_arr,np_arr],axis=0)\n",
    "    np_arr=np_arr.transpose((1,2,0))\n",
    "    return np_arr\n",
    " \n",
    "path=r\"/home/zhangsf/datasets/marble/VOCpatch_0_1_2_3_4/JPEGImages/A22-24h.png\"\n",
    "bin_data=torchvision.io.read_file(path)#加载二进制数据\n",
    "img=torchvision.io.decode_image(bin_data)/255#解码成CHW的图片\n",
    "img=img.unsqueeze(0)#变成BCHW的数据，B==1; squeeze\n",
    "input_tensor=torchvision.transforms.functional.resize(img,[400, 800])\n",
    " \n",
    "#对图像进行水平翻转，得到两个数据\n",
    "input_tensors=torch.cat([input_tensor, input_tensor.flip(dims=(3,))],axis=0)\n",
    " \n",
    "model = VGGUNET2(num_classes=2)\n",
    "resume=\"/home/zhangsf/code/saved/marblenet/02-09_19-36/checkpoint-epoch350.pth\"\n",
    "config=\"/home/zhangsf/code/saved/marblenet/02-09_19-36/config.json\"\n",
    "config['device'] = \"cuda:1\"\n",
    "device = config['device']\n",
    "model.load_state_dict(torch.load(resume, map_location=device)[\"state_dict\"])\n",
    "target_layers = [model.block2]#如果传入多个layer，cam输出结果将会取均值\n",
    " \n",
    "#cam = GradCAM(model=model, target_layers=target_layers, use_cuda=False)\n",
    "with GradCAM(model=model, target_layers=target_layers, use_cuda=False) as cam:\n",
    "    #targets = [ClassifierOutputTarget(2),ClassifierOutputTarget(2)] #指定查看class_num为2的热力图\n",
    "    # aug_smooth=True, eigen_smooth=True 使用图像增强是热力图变得更加平滑\n",
    "    grayscale_cams = cam(input_tensor=input_tensors, targets=None)#targets=None 自动调用概率最大的类别显示\n",
    "    for grayscale_cam,tensor in zip(grayscale_cams,input_tensors):\n",
    "        #将热力图结果与原图进行融合\n",
    "        rgb_img=tensor2img(tensor)\n",
    "        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "        myimshows([rgb_img, grayscale_cam, visualization],[\"image\",\"cam\",\"image + cam\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "898c5ddecdce42b5bdc393dd6386763dbf22ef0c00172c074d1436c54b06181c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
